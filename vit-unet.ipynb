{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1650695,"sourceType":"datasetVersion","datasetId":976194}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import ViTModel, ViTConfig\nimport os\nfrom tqdm import tqdm\nfrom PIL import Image\nimport torch.nn.functional as F\n\nclass UNetGenerator(nn.Module):\n    def __init__(self, input_channels, output_channels):\n        super(UNetGenerator, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1),  # 224x224 -> 112x112\n            nn.ReLU(),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),             # 112x112 -> 56x56\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1),            # 56x56 -> 28x28\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1),            # 28x28 -> 14x14\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n        )\n\n        self.middle = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=4, stride=1, padding=1),  # Keeps size at 14x14\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=1, padding=1),  # Keeps size at 14x14\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n        )\n\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 14x14 -> 28x28\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),   # 28x28 -> 56x56\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),   # 56x56 -> 112x112\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.ConvTranspose2d(16, output_channels, kernel_size=4, stride=2, padding=1),  # 112x112 -> 224x224\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        # Encoder\n        enc = self.encoder(x)\n        #print(f\"Shape after encoder: {enc.shape}\")  # Check encoder output shape\n        \n        # Middle\n        mid = self.middle(enc)\n        #print(f\"Shape after middle: {mid.shape}\")  # Check shape after middle layer\n        \n        # Decoder\n        dec = self.decoder(mid)\n        #print(f\"Shape after decoder: {dec.shape}\")  # Final generator output shape\n        return dec\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, input_channels):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(128, 1, kernel_size=4, stride=2, padding=0),  # Ensures output is [B, 1, 1, 1]\n            nn.Sigmoid(),\n        )\n    \n    def forward(self, x):\n        return self.model(x)\n\n# Dataset and DataLoader\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\nclass KITTIDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = sorted([os.path.join(root_dir, img) for img in os.listdir(root_dir) if img.endswith('.png') or img.endswith('.jpg')])\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, 0  # Dummy label as GANs don't require labels\n\ndataset = KITTIDataset(\"/kaggle/input/kitti-dataset/data_object_image_2/training/image_2\", transform=transform)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n\n# Initialize Models\ngenerator = UNetGenerator(input_channels=128, output_channels=3).cuda()\ndiscriminator = Discriminator(input_channels=3).cuda()\nvit_config = ViTConfig(hidden_size=128, num_attention_heads=4, num_hidden_layers=6)\nvit_encoder = ViTModel(vit_config).cuda()\n\n# Optimizers\nopt_gen = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\nopt_disc = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\n# Loss Functions\nadversarial_loss = nn.BCELoss()\nreconstruction_loss = nn.MSELoss()\n\n# Training Loop\nepochs = 100\nfor epoch in range(epochs):\n    for real_images, _ in tqdm(dataloader):\n        real_images = real_images.cuda()\n        batch_size = real_images.size(0)\n        valid = torch.ones((batch_size, 1)).cuda()\n        fake = torch.zeros((batch_size, 1)).cuda()\n\n        # Train Generator\n        opt_gen.zero_grad()\n\n        #print(f\"Input shape: {real_images.shape}\")  # Shape of input image batch\n\n        # Get the output from ViT encoder\n        output = vit_encoder(real_images).last_hidden_state\n        #print(f\"Output shape (ViT): {output.shape}\")  # ViT encoder output\n        \n        # Exclude the CLS token\n        patch_embeddings = output[:, 1:, :]  # Remove the CLS token\n        #print(f\"Patch embeddings shape: {patch_embeddings.shape}\")  # After excluding CLS token\n        \n        # Reshape the output to feed into the generator\n        num_patches = int(patch_embeddings.shape[1] ** 0.5)  # Compute square root of number of patches\n        z = patch_embeddings.permute(0, 2, 1).view(batch_size, 128, num_patches, num_patches)\n        #print(f\"Final tensor shape (z): {z.shape}\")  # After reshaping for generator\n\n        # After shaping z to [batch, 128, 14, 14], upsample it:\n        z_upsampled = F.interpolate(z, size=(224, 224), mode='bilinear', align_corners=False)\n        gen_images = generator(z_upsampled)\n\n        #print(f\"Generated images shape: {gen_images.shape}\")\n\n\n        valid = torch.ones_like(discriminator(gen_images)).cuda()  # Match shape dynamically\n        fake = torch.zeros_like(discriminator(gen_images)).cuda()  # Match shape dynamically\n\n\n        #print(f\"Discriminator output shape: {discriminator(gen_images).shape}\")\n        #print(f\"Valid tensor shape: {valid.shape}\")\n\n        \n        g_loss = adversarial_loss(discriminator(gen_images), valid) + reconstruction_loss(gen_images, real_images)\n        g_loss.backward()\n        opt_gen.step()\n\n        # Train Discriminator\n        opt_disc.zero_grad()\n        real_loss = adversarial_loss(discriminator(real_images), valid)\n        fake_loss = adversarial_loss(discriminator(gen_images.detach()), fake)\n        d_loss = (real_loss + fake_loss) / 2\n        d_loss.backward()\n        opt_disc.step()\n\n    print(f\"Epoch {epoch}/{epochs} | Generator Loss: {g_loss.item()} | Discriminator Loss: {d_loss.item()}\")\n\n    # Save model checkpoint\n    if epoch % 10 == 0:\n        torch.save(generator.state_dict(), f\"generator_epoch_{epoch}.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:37:14.620161Z","iopub.execute_input":"2024-12-07T16:37:14.620494Z","iopub.status.idle":"2024-12-07T20:08:25.987840Z","shell.execute_reply.started":"2024-12-07T16:37:14.620463Z","shell.execute_reply":"2024-12-07T20:08:25.986932Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 234/234 [03:01<00:00,  1.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0/100 | Generator Loss: 1.0204671621322632 | Discriminator Loss: 0.5757521390914917\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100 | Generator Loss: 0.8944224119186401 | Discriminator Loss: 0.6046009659767151\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:09<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/100 | Generator Loss: 0.9148299098014832 | Discriminator Loss: 0.662074863910675\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:08<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/100 | Generator Loss: 0.9174225926399231 | Discriminator Loss: 0.6196024417877197\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:09<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/100 | Generator Loss: 0.8649089336395264 | Discriminator Loss: 0.6286202669143677\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:11<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/100 | Generator Loss: 0.8477680683135986 | Discriminator Loss: 0.6478431224822998\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:11<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/100 | Generator Loss: 0.8825801610946655 | Discriminator Loss: 0.6523526310920715\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:08<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/100 | Generator Loss: 0.8609124422073364 | Discriminator Loss: 0.6547753810882568\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:10<00:00,  1.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/100 | Generator Loss: 0.8716676235198975 | Discriminator Loss: 0.676280677318573\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/100 | Generator Loss: 0.7923703193664551 | Discriminator Loss: 0.6853745579719543\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/100 | Generator Loss: 0.8484306335449219 | Discriminator Loss: 0.641687273979187\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/100 | Generator Loss: 0.8051302433013916 | Discriminator Loss: 0.7096637487411499\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/100 | Generator Loss: 0.8951003551483154 | Discriminator Loss: 0.6600557565689087\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/100 | Generator Loss: 0.9105572700500488 | Discriminator Loss: 0.6478037238121033\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/100 | Generator Loss: 0.9278598427772522 | Discriminator Loss: 0.6569019556045532\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/100 | Generator Loss: 0.8418715596199036 | Discriminator Loss: 0.6609691977500916\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/100 | Generator Loss: 0.8129839897155762 | Discriminator Loss: 0.673197865486145\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:11<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/100 | Generator Loss: 0.8519625067710876 | Discriminator Loss: 0.6657014489173889\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/100 | Generator Loss: 0.8247244954109192 | Discriminator Loss: 0.6730898022651672\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:08<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/100 | Generator Loss: 0.8537623882293701 | Discriminator Loss: 0.6696504950523376\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/100 | Generator Loss: 0.8032670021057129 | Discriminator Loss: 0.6897951364517212\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21/100 | Generator Loss: 0.8628685474395752 | Discriminator Loss: 0.6753075122833252\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:08<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22/100 | Generator Loss: 0.8021018505096436 | Discriminator Loss: 0.6760892868041992\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23/100 | Generator Loss: 0.8990809917449951 | Discriminator Loss: 0.6575722098350525\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24/100 | Generator Loss: 0.8075598478317261 | Discriminator Loss: 0.6773127913475037\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25/100 | Generator Loss: 0.8177750110626221 | Discriminator Loss: 0.6819217801094055\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26/100 | Generator Loss: 0.7951428890228271 | Discriminator Loss: 0.672096848487854\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27/100 | Generator Loss: 0.8677485585212708 | Discriminator Loss: 0.6698155403137207\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28/100 | Generator Loss: 0.8236097693443298 | Discriminator Loss: 0.702592134475708\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:08<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29/100 | Generator Loss: 0.8524274230003357 | Discriminator Loss: 0.6662145853042603\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:02<00:00,  1.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30/100 | Generator Loss: 0.8164740800857544 | Discriminator Loss: 0.682445764541626\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31/100 | Generator Loss: 0.8253035545349121 | Discriminator Loss: 0.6872433423995972\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32/100 | Generator Loss: 0.8390141725540161 | Discriminator Loss: 0.6749070882797241\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33/100 | Generator Loss: 0.8341342806816101 | Discriminator Loss: 0.6916966438293457\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34/100 | Generator Loss: 0.8566270470619202 | Discriminator Loss: 0.6547859907150269\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35/100 | Generator Loss: 0.8684451580047607 | Discriminator Loss: 0.7392113208770752\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:08<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36/100 | Generator Loss: 0.8120260834693909 | Discriminator Loss: 0.663360595703125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37/100 | Generator Loss: 0.781323254108429 | Discriminator Loss: 0.6838430762290955\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38/100 | Generator Loss: 0.7895152568817139 | Discriminator Loss: 0.6805707216262817\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39/100 | Generator Loss: 0.8016489148139954 | Discriminator Loss: 0.6808002591133118\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40/100 | Generator Loss: 0.8106327056884766 | Discriminator Loss: 0.688918948173523\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41/100 | Generator Loss: 0.8124960064888 | Discriminator Loss: 0.6835490465164185\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42/100 | Generator Loss: 0.787822961807251 | Discriminator Loss: 0.6889368295669556\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43/100 | Generator Loss: 0.8456916809082031 | Discriminator Loss: 0.6765224933624268\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44/100 | Generator Loss: 0.8331030011177063 | Discriminator Loss: 0.6788831949234009\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45/100 | Generator Loss: 0.7839365601539612 | Discriminator Loss: 0.6863541603088379\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46/100 | Generator Loss: 0.8360519409179688 | Discriminator Loss: 0.6839478611946106\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47/100 | Generator Loss: 0.8060393929481506 | Discriminator Loss: 0.6806306838989258\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48/100 | Generator Loss: 0.7386088371276855 | Discriminator Loss: 0.7018717527389526\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49/100 | Generator Loss: 0.8969568014144897 | Discriminator Loss: 0.6736968159675598\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50/100 | Generator Loss: 0.7967444658279419 | Discriminator Loss: 0.7000998258590698\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:01<00:00,  1.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 51/100 | Generator Loss: 0.796057939529419 | Discriminator Loss: 0.6890507340431213\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 52/100 | Generator Loss: 0.8251014947891235 | Discriminator Loss: 0.666301965713501\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 53/100 | Generator Loss: 0.8232868313789368 | Discriminator Loss: 0.6785391569137573\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 54/100 | Generator Loss: 0.8287081718444824 | Discriminator Loss: 0.6807428598403931\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:02<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 55/100 | Generator Loss: 0.8102254867553711 | Discriminator Loss: 0.6958191394805908\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:01<00:00,  1.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 56/100 | Generator Loss: 0.7907676696777344 | Discriminator Loss: 0.7077564001083374\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 57/100 | Generator Loss: 0.7805426716804504 | Discriminator Loss: 0.680925190448761\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 58/100 | Generator Loss: 0.7663694024085999 | Discriminator Loss: 0.6856697797775269\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:02<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 59/100 | Generator Loss: 0.7818620800971985 | Discriminator Loss: 0.706287145614624\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 60/100 | Generator Loss: 0.8768738508224487 | Discriminator Loss: 0.6662469506263733\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:02<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 61/100 | Generator Loss: 0.7843970060348511 | Discriminator Loss: 0.6893675327301025\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 62/100 | Generator Loss: 0.8284315466880798 | Discriminator Loss: 0.6790874004364014\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 63/100 | Generator Loss: 0.785324215888977 | Discriminator Loss: 0.7036466598510742\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 64/100 | Generator Loss: 0.8799338936805725 | Discriminator Loss: 0.6578869819641113\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 65/100 | Generator Loss: 0.8422272801399231 | Discriminator Loss: 0.6843662261962891\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 66/100 | Generator Loss: 0.8745805621147156 | Discriminator Loss: 0.6813532114028931\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:02<00:00,  1.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 67/100 | Generator Loss: 0.7499045133590698 | Discriminator Loss: 0.7044329643249512\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:02<00:00,  1.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 68/100 | Generator Loss: 0.8427927494049072 | Discriminator Loss: 0.6611875295639038\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 69/100 | Generator Loss: 0.7960138320922852 | Discriminator Loss: 0.6697055101394653\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 70/100 | Generator Loss: 0.8366439938545227 | Discriminator Loss: 0.6792103052139282\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 71/100 | Generator Loss: 0.770671010017395 | Discriminator Loss: 0.6804149150848389\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 72/100 | Generator Loss: 0.7552427053451538 | Discriminator Loss: 0.6939644813537598\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 73/100 | Generator Loss: 0.7815706133842468 | Discriminator Loss: 0.6834418177604675\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 74/100 | Generator Loss: 0.8751962184906006 | Discriminator Loss: 0.673210620880127\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 75/100 | Generator Loss: 0.775391697883606 | Discriminator Loss: 0.7037074565887451\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 76/100 | Generator Loss: 0.7334122657775879 | Discriminator Loss: 0.699561595916748\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 77/100 | Generator Loss: 0.8079275488853455 | Discriminator Loss: 0.694121241569519\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 78/100 | Generator Loss: 0.7455877065658569 | Discriminator Loss: 0.7043793797492981\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 79/100 | Generator Loss: 0.817805826663971 | Discriminator Loss: 0.6662888526916504\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 80/100 | Generator Loss: 0.7745766043663025 | Discriminator Loss: 0.6922572255134583\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 81/100 | Generator Loss: 0.8213468790054321 | Discriminator Loss: 0.6743678450584412\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 82/100 | Generator Loss: 0.7712714076042175 | Discriminator Loss: 0.6945867538452148\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 83/100 | Generator Loss: 0.8062005639076233 | Discriminator Loss: 0.6746228933334351\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 84/100 | Generator Loss: 0.7782719135284424 | Discriminator Loss: 0.6844481825828552\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 85/100 | Generator Loss: 0.8368995189666748 | Discriminator Loss: 0.6862497329711914\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 86/100 | Generator Loss: 0.8261236548423767 | Discriminator Loss: 0.6736732125282288\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 87/100 | Generator Loss: 0.7959935069084167 | Discriminator Loss: 0.696147084236145\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 88/100 | Generator Loss: 0.7963318824768066 | Discriminator Loss: 0.6735004186630249\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:07<00:00,  1.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 89/100 | Generator Loss: 0.787826418876648 | Discriminator Loss: 0.6843894720077515\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 90/100 | Generator Loss: 0.8171634078025818 | Discriminator Loss: 0.6750611066818237\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:06<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 91/100 | Generator Loss: 0.8015762567520142 | Discriminator Loss: 0.67087322473526\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 92/100 | Generator Loss: 0.818140983581543 | Discriminator Loss: 0.6868385076522827\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 93/100 | Generator Loss: 0.740729570388794 | Discriminator Loss: 0.6803363561630249\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 94/100 | Generator Loss: 0.7625223994255066 | Discriminator Loss: 0.706882655620575\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:04<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 95/100 | Generator Loss: 0.7480475902557373 | Discriminator Loss: 0.6965979337692261\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 96/100 | Generator Loss: 0.80366450548172 | Discriminator Loss: 0.7076535224914551\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 97/100 | Generator Loss: 0.8222793936729431 | Discriminator Loss: 0.685386061668396\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:05<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 98/100 | Generator Loss: 0.7330008745193481 | Discriminator Loss: 0.6944208741188049\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 234/234 [02:03<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 99/100 | Generator Loss: 0.7911421656608582 | Discriminator Loss: 0.6760014295578003\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"### Load the model and test","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision.utils import save_image\n\n# Assume you are in the same environment where UNetGenerator is defined\n# or have imported it from your module.\n\n# Create a new instance of the generator and load the weights\ngenerator = UNetGenerator(input_channels=128, output_channels=3).cuda()\ncheckpoint_path = \"/kaggle/working/generator_epoch_90.pth\"  \ngenerator.load_state_dict(torch.load(checkpoint_path))\ngenerator.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T20:12:20.530645Z","iopub.execute_input":"2024-12-07T20:12:20.531478Z","iopub.status.idle":"2024-12-07T20:12:20.574382Z","shell.execute_reply.started":"2024-12-07T20:12:20.531440Z","shell.execute_reply":"2024-12-07T20:12:20.573549Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/4223602956.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  generator.load_state_dict(torch.load(checkpoint_path))\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"UNetGenerator(\n  (encoder): Sequential(\n    (0): Conv2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): ReLU()\n    (5): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): ReLU()\n    (8): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU()\n  )\n  (middle): Sequential(\n    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n  )\n  (decoder): Sequential(\n    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU()\n    (9): ConvTranspose2d(16, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (10): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"#### Using ViT. Requires sample image","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nfrom torchvision import transforms\nimport torch.nn.functional as F\n\n# Load ViT and set to eval mode\nvit_encoder = ViTModel(ViTConfig(hidden_size=128, num_attention_heads=4, num_hidden_layers=6)).cuda()\nvit_encoder.eval()\n\n# Same transformation used during training\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\n# Load a sample image\ntest_image = Image.open(\"/kaggle/input/kitti-dataset/data_object_image_2/testing/image_2/000000.png\").convert(\"RGB\")\ntest_image = transform(test_image).unsqueeze(0).cuda()  # shape: [1, 3, 224, 224]\n\n# Get ViT embeddings\nwith torch.no_grad():\n    output = vit_encoder(test_image).last_hidden_state  # shape: [1, 197, 128]\n\n# Remove CLS token\npatch_embeddings = output[:, 1:, :]  # shape: [1, 196, 128]\n\n# Reshape into spatial dimensions\nnum_patches = int(patch_embeddings.shape[1] ** 0.5)  # Should be 14 for 14x14\nz = patch_embeddings.permute(0, 2, 1).view(1, 128, num_patches, num_patches)  # [1,128,14,14]\n\n# Upsample to 224x224 if that's what your generator expects\nz_upsampled = F.interpolate(z, size=(224, 224), mode='bilinear', align_corners=False)  # [1,128,224,224]\n\n# Generate image\nwith torch.no_grad():\n    gen_images = generator(z_upsampled)  # [1, 3, 224, 224]\n\n# Save the generated image\n# If you normalized your data with mean=0.5 and std=0.5, convert back\ngen_images = gen_images * 0.5 + 0.5\nsave_image(gen_images, \"generated_sample.png\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T20:13:13.784851Z","iopub.execute_input":"2024-12-07T20:13:13.785398Z","iopub.status.idle":"2024-12-07T20:13:13.944708Z","shell.execute_reply.started":"2024-12-07T20:13:13.785361Z","shell.execute_reply":"2024-12-07T20:13:13.943845Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"#### Using noise","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision.utils import save_image\nimport torch.nn.functional as F\n\n# Create random input (matching the shape generator expects)\n# The generator expects [N, 128, 224, 224] since we upsampled z\nz_random = torch.randn(1, 128, 224, 224).cuda()\n\nwith torch.no_grad():\n    gen_images = generator(z_random)  # [1, 3, 224, 224]\n\n# Convert back to [0,1] range if you used the same normalization\ngen_images = gen_images * 0.5 + 0.5\n\n# Save the generated image\nsave_image(gen_images, \"generated_sample_random.png\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T20:15:48.488305Z","iopub.execute_input":"2024-12-07T20:15:48.488741Z","iopub.status.idle":"2024-12-07T20:15:48.570818Z","shell.execute_reply.started":"2024-12-07T20:15:48.488706Z","shell.execute_reply":"2024-12-07T20:15:48.569887Z"}},"outputs":[],"execution_count":36}]}